# API de Transcri√ß√£o de √Åudio com Whisper

Esta √© uma API REST para transcri√ß√£o de √°udio usando o modelo Whisper da OpenAI, containerizada com Docker.

## üöÄ Caracter√≠sticas

- **Endpoint de transcri√ß√£o**: `/transcribe`
- **M√∫ltiplos formatos**: WAV, MP3, MP4, MPEG, MPGA, M4A, OGG, FLAC
- **M√∫ltiplos idiomas**: Detec√ß√£o autom√°tica ou especifica√ß√£o manual
- **Modelos flex√≠veis**: tiny, base, small, medium, large
- **Containerizado**: Pronto para deploy com Docker
- **Health check**: Endpoint para monitoramento

## üìÅ Estrutura dos Arquivos

```
whisper-transcription-api/
‚îú‚îÄ‚îÄ app.py              # Aplica√ß√£o Flask principal
‚îú‚îÄ‚îÄ Dockerfile          # Configura√ß√£o do container
‚îú‚îÄ‚îÄ docker-compose.yml  # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias Python
‚îú‚îÄ‚îÄ test_api.py        # Script para testar a API
‚îî‚îÄ‚îÄ README.md          # Este arquivo
```

## üõ†Ô∏è Instala√ß√£o e Execu√ß√£o

### Op√ß√£o 1: Docker Compose (Recomendado)

1. **Clone ou crie os arquivos** em um diret√≥rio
2. **Execute o comando**:
   ```bash
   docker-compose up --build
   ```

### Op√ß√£o 2: Docker Build Manual

1. **Construa a imagem**:
   ```bash
   docker build -t whisper-api .
   ```

2. **Execute o container**:
   ```bash
   docker run -p 5000:5000 whisper-api
   ```

### Op√ß√£o 3: Execu√ß√£o Local (sem Docker)

1. **Instale as depend√™ncias**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Execute a aplica√ß√£o**:
   ```bash
   python app.py
   ```

## üì° API Endpoint

### POST `/transcribe`
**√önico endpoint da API** - transcreve um arquivo de √°udio.

**Par√¢metros**:
- `file` (obrigat√≥rio): Arquivo de √°udio
- `language` (opcional): C√≥digo do idioma (ex: 'pt', 'en', 'es')
- `model_size` (opcional): Tamanho do modelo (tiny, base, small, medium, large)

**Exemplo de uso com cURL**:
```bash
curl -X POST \
  -F "file=@audio.wav" \
  -F "language=pt" \
  -F "model_size=base" \
  http://localhost:5000/transcribe
```

**Exemplo com Python requests**:
```python
import requests

with open('audio.wav', 'rb') as f:
    files = {'file': f}
    data = {'language': 'pt', 'model_size': 'base'}
    response = requests.post('http://localhost:5000/transcribe', files=files, data=data)
    result = response.json()
    print(result['transcription'])
```

**Resposta de sucesso**:
```json
{
  "filename": "audio.wav",
  "transcription": "Texto completo da transcri√ß√£o...",
  "language": "pt",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "Primeiro segmento de texto..."
    }
  ]
}
```

### Documenta√ß√£o Interativa
Acesse `http://localhost:5000/docs` para a documenta√ß√£o Swagger autom√°tica, onde voc√™ pode:
- Ver todos os par√¢metros detalhadamente
- Testar a API diretamente no navegador
- Ver exemplos de resposta

## üß™ Testando a API

Use o script de teste fornecido:

```bash
# Instalar requests se necess√°rio
pip install requests

# Teste b√°sico
python test_api.py audio.wav

# Com idioma espec√≠fico
python test_api.py audio.wav pt

# Com modelo espec√≠fico
python test_api.py audio.wav pt small
```

## üîß Configura√ß√µes

### Limites da Aplica√ß√£o
- **Tamanho m√°ximo do arquivo**: 50MB
- **Formatos suportados**: wav, mp3, mp4, mpeg, mpga, m4a, ogg, flac

### Modelos Whisper Dispon√≠veis
- **tiny**: Mais r√°pido, menos preciso
- **base**: Balanceado (padr√£o)
- **small**: Boa precis√£o
- **medium**: Alta precis√£o
- **large**: M√°xima precis√£o, mais lento

### Vari√°veis de Ambiente
- `FLASK_ENV`: Ambiente da aplica√ß√£o (production/development)

## üê≥ Docker

### Volumes
- `whisper_cache`: Cache dos modelos Whisper para melhor performance

### Health Check
O container inclui health check autom√°tico que verifica o endpoint `/health` a cada 30 segundos.

## üìä Monitoramento

### Logs
Os logs da aplica√ß√£o incluem informa√ß√µes sobre:
- Carregamento dos modelos
- Processamento de arquivos
- Erros e exce√ß√µes

### Status Codes
- `200`: Sucesso
- `400`: Erro de valida√ß√£o (arquivo inv√°lido, par√¢metros incorretos)
- `500`: Erro interno do servidor

## üöÄ Deploy em Produ√ß√£o

### Considera√ß√µes
1. **Recursos**: Modelos maiores requerem mais RAM e CPU
2. **Storage**: Considere usar volumes persistentes para cache
3. **Seguran√ßa**: Implemente autentica√ß√£o se necess√°rio
4. **Rate Limiting**: Considere limitar requests por usu√°rio
5. **Load Balancer**: Para alta disponibilidade

### Exemplo com nginx
```nginx
upstream whisper_api {
    server localhost:5000;
}

server {
    listen 80;
    server